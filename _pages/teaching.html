---
layout: archive
title: "Research Experience"
permalink: /research/
author_profile: true
---

<!-- {% include base_path %}

{% for post in site.teaching reversed %}
  {% include archive-single.html %}
{% endfor %} -->
  
<p><strong>Siebel School of Computing and Data Science. University of Illinois Urbana-Champaign</strong><br> 
Undergraduate Research Scholar, TRAILS Lab | Jan 2023 - Present<br>
Mentor: Dr. Kathryn Cunningham <br>
  <ul>
    <li>
      Pursuing research to design a socio-technical system to assist instructors in efficiently identifying common code patterns in application-focused domains like web development with Django, that interest non-computer science majors.
    </li>
                
    <li>
      Implementing a web interface to formulate a question generator that creates various types of questions, including multiple-choice, reordering, and fill-in-the-blank tasks using programming patterns.
    </li>
    <li>
      Designed an LLM-powered pipeline that can suggest candidate programming patterns using chain-of-thought prompting to identify code examples and clustering similar code snippets into patterns. 
    </li>  
    <li>
      Co-administered a design workshop with this design artifact with 7 experts from 3 domains to understand what interactions best assist instructors in navigating these candidate patterns efficiently and effectively.
    </li>
    <li>
      Developed a web application framework using HTML/CSS, JavaScript, and Flask to create PLAID, an interface that assists instructors in designing programming patterns in any application-focused domain as part of the Illinois CS Summer Research Program.
    </li>
    <li>
      Conducted an evaluation study with 12 instructors from 3 domains using validated survey instruments, including the NASA TLX cognitive load survey and PSSUQ usability survey in a think aloud setting. 
    </li>
    <li>
      Grounded the design of the LLM-powered pipeline using results from a formative study with 10 instructors. Performed qualitative coding on the interview transcripts to thematically analyze how educators find and create programming patterns and its key challenges.
    </li>
    <li>
      Presented preliminary ideas to identify programming patterns and evaluate their quality as a poster at ACM Conference on International Computing Education Research in Jul. 2023.
    </li>
  </ul>            
</p>
                
<p><strong>Human-Computer Interaction Institute. Carnegie Mellon University (& University of Memphis)</strong>  <br>             
  Undergraduate Research Intern, GEM Team | May 2024 - Present<br>            
  Mentors: Dr. Jionghao Lin, Dr. John Hollander, Liang Zhang, Dr. John Sabatini <br>
  <ul>            
    <li> 
      Examining the inconsistencies and weaknesses in the properties of large language models in performing reading comprehension tasks. Submitting the findings as a proposal to HCI International 2025 Conference.
    </li>
                
    <li>  
      Inspecting the quality of these multiple choice questions using linguistic characteristic comparisons with human-generated questions.
    </li>
                
    <li>
      Coded a RAG-based pipeline for question generation using a few-shot prompting approach to the OpenAI API with readings given to students as context.
    </li>          
    <li>
      Assessed the accuracy of ChatGPT in answering human-generated questions and evaluated its question-generation capabilities in reading comprehension.
    </li>
    <li>
      Developed a tutor-learner simulation with Autogen,  enabling a multi-agent interaction-based environment where the learner agent answered questions generated by the tutor agent, and the tutor adapted the difficulty of the questions depending on the learners' responses. 
    </li>
  </ul>            
</p>

<p><strong>Siebel School of Computing and Data Science. University of Illinois Urbana-Champaign</strong>  <br>             
  Undergraduate Research Scholar, SCUBA Lab | Aug 2023 - Present<br>            
  Mentor: Dr. Eshwar Chandrasekharan <br>     
  <ul>            
    <li>            
      Designing a quasi-experimental study to identify how exposure to positive and negative feedback mechanisms on Reddit (gilds, upvotes, removals) affect users' longitudinal behavior.
    </li>                            
    <li>            
      Identifying feedback mechanisms, including gilds, upvotes, and removals, and measurable outcomes like positive affect and negative affect, to analyze any significant differences in user activity due to exposure. 
    </li>            
    <li>            
      Implementing an algorithm to identify treatment and control groups with pre-treatment and post-treatment comments on a large dataset of more than 1,000,000 data points and leveraged LIWC analysis to measure outcomes. 
    </li>       
    <li>
      Performing stratified propensity score matching to group treatment and control authors with the most similar characteristics used DiD estimation to reveal lexico-semantic and content-based changes in user activity.
    </li>
  </ul>            
</p>
                
<p><strong>Siebel School of Computing and Data Science. University of Illinois Urbana-Champaign</strong>  <br>             
  Undergraduate Research Scholar, OnCARE Lab | Aug 2023 - Present<br>            
  Mentor: Dr. Koustuv Saha <br>            
  <ul>            
    <li>            
      Examined the capabilities of LLMs in supporting users in Alzheimerâ€™s related online communities using causal inference analysis. 
    </li>            
    <li>            
      Collected top 50 questions from the r/Alzheimers subreddit using the PRAW API, 70 posts from Alzconnected.org, and queried ChatGPT using the OpenAI API for responses to posts from these social media platforms. 
    </li>            
    <li>            
      Employed inductive coding analysis to observe differences between human-authored comments and LLM-generated content. 
    </li>
    <li>
      Deployed open-source LLMs (Llama and Mistral) on GPUs and the used OpenAI API to gather LLM-generated content for a large-scale quantitative evaluation of psycholinguistics, lexico-semantics, and content level differences. 
    </li>
    <li>
      Designed pipelines for employing pre-trained classifiers for psycholinguistic analysis, including empathy and formality classifiers. 
    </li>
  </ul>
</p>
